---
title: "Single cell Project"
author: "Vittoria Ossanna"
output:
  pdf_document: default
  html_document:
    df_print: paged
editor_options:
  markdown:
    wrap: sentence
---

#### Load the necessary packages to perform the analysis

```{r, warning = F, message = F}

library(tidyverse) # collection of packages for tidy data analysis (ggplot, dplyr, ...)
library(Seurat) # single cell analysis (Check that the version is at least 4.0.0)
library(patchwork) # combine separate ggplots into the same graphic
```

### Reading the data

In this step, I am loading data from the file VPV.rds, a file containing an unknown sample obtained from either mice or human tissues.
After tissue dissociation, cells were sorted by FACS and scRNA-seq libraries were prepared with the Smart-Seq2 protocol/platform.
The starting point is a digital count matrix with mouse or human genes as features.

```{r, warning = F, message = F}
data.raw <- readRDS("./data/VPV.rds")
```

In this step, I am initializing the Seurat object with the digital count matrix.
We are starting with a count table containing 4148 samples and 23433 features (as genes).

```{r, warning = F, message = F}
data <- CreateSeuratObject(counts = data.raw)
```

# 1. Quality control and filtering

In the current Section, I use standard methods of quality control and filtering to obtain a cleaned matrix of data.

## Filtering based on the percentage of mitocondrial, ribosomial and hemoglobin genes

We filter out genes with increased number of genes that map to a mitochondrial genome because low-quality or dying cells often exhibit extensive mitochondrial contamination.
In the same manner we will calculate the proportion gene expression that comes from ribosomal proteins.
Finally, with the same method we will calculate proportion hemoglobin genes, which can give an indication of red blood cell contamination.
I believe that this control has no use in this project because I do not know the composition of my sample, therefore, avoiding to consider hemoglobin-related genes could lead to errors.

As indicated in the assignment, mitochondrial genes might be missing from the count matrix, therefore I used spike-in RNAs, all starting with "ERCC", as an alternative quality control.
ERCC stands for External RNA Controls Consortium.

```{r qc_metrics, warning=F, message=F}
data[["percent_mt"]] <- PercentageFeatureSet(data, pattern = "^MT-")
data[["percent_ribo"]] <- PercentageFeatureSet(data, "^RP[SL]")
# data[["percent_hb"]] <- PercentageFeatureSet(data, "^HB[^(P)]")
max(data[["percent_mt"]])
max(data[["percent_ribo"]])
# max(data[["percent_hb"]])

data[["percent_ERCC"]] <- PercentageFeatureSet(data, "^ERCC")
max(data[["percent_ERCC"]])
```

From this analysis, it seems that there is no instance that correspond to any of these genes.
Anyhow, the alternative filtering based on ERCC seems to produce non-null values.
I will use in the next steps this percentage for filtering.

### Updating dataset with ERCC filtering

This chunk is dedicate to the update of the data excluding all cells that present more than 5% of genes belonging to ERCC.

```{r}
data <- subset(data, percent_ERCC < 5)
```

## Filtering based on unique number of genes detected in each cell and total number of molecules detected within a cell

A standard approach is to filter cells with low amount of reads as well as genes that are present in at least a certain amount of cells.
Here we will only consider cells with at least 200 detected genes and genes need to be expressed in at least 3 cells.

```{r, warning=F, message=F}
# selecting all features and cells with minimum requirement
selected_c <- WhichCells(data, expression = nFeature_RNA > 200)
selected_f <- rownames(data)[Matrix::rowSums(data) > 3]

data.filt <- subset(data, features = selected_f, cells = selected_c)
# dim(data.filt)
```

Extremely high number of detected genes could indicate doublets.
However, depending on the cell type composition in my sample, I may have cells with higher number of genes (and also higher counts) from one cell type.

A clever method to identify a threshold for doublet consideration, is the following:
we plot a violin plot the counts, we expect three areas: one in which we have the desired data, one in which we have too little counts, and one in which we have artifacts, as doublets. We use a graphical insights from this plot to find a threshold for doublets.

```{r, warning=F}
dim(data.filt)

# from this plot we can define a lower and upper bound for out cleaning
VlnPlot(data.filt, features = c("nCount_RNA"), y.max = 3e+6) & geom_hline(yintercept = 750000) & geom_hline(yintercept = 100000)

high.data <- WhichCells(data.filt, expression = nCount_RNA > 750000)
low_data <- WhichCells(data.filt, expression = nCount_RNA < 100000)

# remove these cells
final.data <- setdiff(WhichCells(data.filt),c(high.data, low_data))

# update the dataset with only genes that passed the filetring
data.filt <- data.filt[, colnames(data.filt) %in% final.data]

# check dimension of final filtered dataset
dim(data.filt)

```

### Plot QC for ERCC genes

Now we can plot some of the QC-features to get visual insights.

```{r}
library(gridExtra)

p1<- VlnPlot(data.filt, features = c("nFeature_RNA"), pt.size = 0.01) + theme(legend.position = "none", axis.title.x = element_blank())
p2<- VlnPlot(data.filt, features = c("nCount_RNA"), pt.size = 0.01) + theme(legend.position = "none", axis.title.x = element_blank())
p3<- VlnPlot(data.filt, features = c("percent_ERCC"), pt.size = 0.01) + theme(legend.position = "none", axis.title.x = element_blank())

gridExtra::grid.arrange(p1, p2, p3, ncol = 3)
```

```{r qc_scatter, warning=F, message=F}
plot1 <- FeatureScatter(data.filt, feature1 = "nCount_RNA", feature2 = "percent_ERCC") + theme(legend.position = "none") + labs(title = NULL)
plot2 <- FeatureScatter(data.filt, feature1 = "nCount_RNA", feature2 = "nFeature_RNA") + theme(legend.position = "none") + labs(title = NULL)
plot1 + plot2
```

## Filtering considerations

From the filtering based on presence of ERCC (excluding all cells that present more than 5% of ERCC transcripts detected) and the filtering based on a lower bound of counts (for both cells and genes) and upper bound (associated to Doublets), I recovered a dataset that contains 2284 cells and 22012 features.

# 2. Normalization, identification of variable features, scaling

## Data Normalization

In the realm of data analysis, ensuring proper normalization for both inter-sample and intra-sample comparisons is crucial to obtain unbiased results.
To achieve this goal in the current project, I employ a Log-Normalization method.
This approach normalizes the measurement of feature expression for each cell based on the total expression, applies a scaling factor (10,000 by default), and subsequently transforms the results using a logarithmic function.
The resulting normalized data is stored within the `data.filt[["RNA"]]@data` container.

```{r, warning = F, message=F}

data.filt <- NormalizeData(data.filt, 
                           normalization.method = "LogNormalize", 
                           scale.factor = 10000)

# data.filt[["RNA"]]@data[1:10, 1:30]

```

## Feature Selection

In this section, I isolate a subset of features characterized by significant cell-to-cell variability.
Concentrating on these genes in subsequent analyses enhances the ability to emphasize biological signals within single-cell datasets.

```{r, message = F, warning=F}
data.filt <- FindVariableFeatures(data.filt, 
                                  selection.method = "vst", 
                                  nfeatures = 2000)

top10 <- head(VariableFeatures(data.filt), 10)

plot1 <- VariableFeaturePlot(data.filt)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = T)

plot2

```

## Scaling

In this section, I perform a linear transformation to the expression levels of each gene.
This is a standard pre-processing step which is often used before performing dimensionality reduction.
Since - at the end of the day - we are interested in the genes which are expressed in the most different way - we perform this scaling only on the top 2000 genes (identified before).

```{r, warning= F, message=F}
all_genes <- rownames(data.filt)

data.filt <- ScaleData(data.filt, 
                       fetaures = all_genes)

# data.filt[["RNA"]]@scale.data[1:5, 1:10]
```

# 3. Dimensionality reduction

Dimensionality reduction techniques are employed to reduce data complexity in downstream analyses (e.g. clustering) and for data visualization.

## PCA

PCA, or Principal Component Analysis, is a technique used to simplify complex data by transforming it into a lower-dimensional representation while retaining as much original information as possible.
It achieves this by finding a set of new variables called principal components that are uncorrelated and ranked by the amount of variance they explain.
PCA is useful for reducing data dimensionality, preserving essential information, and revealing underlying patterns.

```{r, message=F, warning=F}
data.filt <- RunPCA(data.filt, 
                    features = VariableFeatures(object = data.filt))

DimPlot(data.filt, reduction = "pca",label = F) +  theme(legend.position = "none")
```

PCA is highly interpretable and efficient, nevertheless it is often not a good idea to use such dimentionality reduction method with Single Cell data, due to their high sparsity and non-linear structure of the data.
For this reason, I use two different non-linear method in the next section to overcome this problem.

### Define number of relevant components

For next steps, I need to derive a proper number of dimensions to use.
In order to do so, I use the heuristic method of the elbow plot: a ranking of principle components based on the percentage of variance explained by each one. In general, the higher the number of component I will use in the next steps, the better. The decrease in its numbers is strictly related to computational time.

```{r}
ElbowPlot(data.filt, ndims = 50)
```

Since the overall dataset would consists in thousands of features, it does not make much sense only to use 7 (even in the elbow is probably there).
If I use 50 feature, the process would be fasten up anyway with a great improvement, without losing to much information.

## t-SNE

t-SNE (t-Distributed Stochastic Neighbor Embedding) is a dimensionality reduction technique used for visualizing complex high-dimensional data.
It works by calculating pairwise similarities between data points, emphasizing close similarities and using Gaussian distributions to define relationships.
It then maps the data to a lower-dimensional space (typically two dimensions) while preserving these pairwise similarities.
t-SNE employs an iterative optimization process to position data points in the lower-dimensional map, ensuring that similar data points remain close, while dissimilar ones are separated.
This makes it a valuable tool for exploring and visualizing intricate data structures and identifying clusters or patterns within the data.

```{r}
data.filt <- RunTSNE(data.filt, 
                     dims = 1:50)
DimPlot(data.filt, reduction = "tsne") + theme(legend.position = "none")
```

## UMAP

UMAP (Uniform Manifold Approximation and Projection) is another dimensionality reduction technique used for visualizing and exploring high-dimensional data.
It shares similarities with t-SNE but offers certain advantages. UMAP constructs a low-dimensional representation by first modeling the data as a topological graph. It focuses on preserving both local and global relationships among data points, leading to more balanced embeddings.
UMAP is known for its efficiency and ability to handle larger datasets compared to t-SNE.
It has gained popularity in various fields for tasks such as visualization, clustering, and data analysis, making it a valuable tool for uncovering patterns and structures within complex datasets. From 2018, UMAP is considered the gold standard for Single Cell analysis. In addition, it preserves better than t-SNE the local and global structure of the data. Nevertheless, UMAP results decrease their interpretability.

```{r, message=F, warning=F}
data.filt <- RunUMAP(data.filt,
                     dims = 1:50)

DimPlot(data.filt, reduction = "umap") + theme(legend.position = "none")
```

# 4. Clustering

The clustering is based on a number of component defined during the PCA. The function implied construct a graph where each cell correspond to a node, and tries to find cliques where the arches are constructed based on the similarity of the expression pattern of two cells.
To cluster the cells we run modularity optimization to group cells into clusters.
The resolution of the clustering is set to 0.5, which should allow us to reconstruct a smaller number of communities. 

```{r, warning=F, message=F}

data.filt <- FindNeighbors(data.filt, dims = 1:50)
data.filt <- FindClusters(data.filt, resolution = 0.5)

head(Idents(data.filt), 5)

```

We now plot again PCA, tSNE and UMAP with labels from clustering to graphically visualize the clustering procedure.

```{r}
DimPlot(data.filt, reduction = "pca")
```

```{r}
DimPlot(data.filt, reduction = "tsne")
```

```{r}
DimPlot(data.filt, reduction = "umap")
```


# 5. Identification of marker genes

We make use of differential expression analysis to identify marker genes.
I will perform a differential expression analysis of each group against every other group (1 vs all).

```{r all_markers, warning=F, message=F}

markers <- FindAllMarkers(data.filt, 
                               only.pos = TRUE, 
                               min.pct = 0.25, 
                               logfc.threshold = 0.25)

top_markers <- markers %>%
    group_by(cluster) %>%
    # order(pbmc_markers$p_val_adj) %>%
    slice_max(n=1,order_by=avg_log2FC)

list_of_markers = top_markers$gene

```

## Visualizing some marker genes

Here, I am plotting a graphic visualization of some of the genes found in the previous summary that exhibit extremely relevant adjusted p-values and high log-fold change.

```{r}
DotPlot(data.filt, features = list_of_markers) + theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
```{r}
FeaturePlot(data.filt, features = list_of_markers[0:4])
FeaturePlot(data.filt, features = list_of_markers[5:9])
```

```{r}
VlnPlot(data.filt, features = list_of_markers[0:4], pt.size = 0)
VlnPlot(data.filt, features = list_of_markers[5:9], pt.size = 0)
```


# 6. Cell cycle analysis

The presence of cell cycle within scRNAseq data may introduce variability.
If the experiment does not focus on the cell cycle, strategies can be employed to address this heterogeneity.
In Seurat, handling cell cycle effects involves computing phase scores using established markers and then removing them during data pre-processing to alleviate the impact of cell cycle heterogeneity on scRNA-seq data.

### Conversion function

Since I am working with mouse genes, I need to convert (sooner or later) gene names from upper to lower case (except the first letter).
Here is a function to do this which will be used during the next steps.

```{r}
convertFirstLetterToUpper <- function(inputVector) {
  result <- sapply(inputVector, function(x) {
    paste0(toupper(substr(x, 1, 1)), tolower(substr(x, 2, nchar(x))))
  })
  return(result)
}
```

### Load marker genes

We use two list of marked (denoting G2/M and S cell phase) which will be use to find matches against the cell from our dataset and convert them into lower case (except first letter).

```{r, warning = F, message=F}

s_genes <- cc.genes$s.genes
s_genes <- convertFirstLetterToUpper(s_genes)
g2m_genes <- cc.genes$g2m.genes
g2m_genes <- convertFirstLetterToUpper(g2m_genes)

```

# Assign cell-cycle score and visualize markers

We assign to each cell a score.
based on presence or absence of the expression of the markers loaded previously.

```{r}

data.filt <- CellCycleScoring(data.filt, s.features = s_genes, g2m.features = g2m_genes, set.ident = T)
head(data.filt[[]], 10)

```

```{r ,warning=F,message=F}
RidgePlot(data.filt, features = c("Mcm5", "Pcna", "Cdk1"), ncol = 3)
```

```{r ,warning=F,message=F}

data.filt <- RunPCA(data.filt, features = c(s_genes, g2m_genes),verbose=F)
DimPlot(data.filt, reduction="pca")
table(data.filt$Phase)

```

By performing a PCA only on genes that are markers for s and g2 phase, we see that the majority of the cells are associated with G1 phase, as for the rest, we have a comparable number of cells in S and in G2 phase.
From the PCA, we can derive that most of the cells (even if not in G1 phase) are spatially close to cells in G1.
Also, we clearly see a hyperplane separating S and G2 phase (horizontally).

# 7. Annotation

We now try to annotate the cell with some annotated dataset.

For each cell in the unknown dataset: 
1. Compute the Spearman correlation between its expression profile and that of each reference sample (measure of robustness to batch effects across datasets) 
2.Define per-label score as a fixed quantile (by default, 0.8) of the correlations across all samples with that label (accounts for differences in the number of reference samples for each label) 
3.Repeat the score calculation for all labels in the reference dataset.
The label with the highest score is used as SingleR's prediction for this cell.

### load required libraries

```{r load_packages,warning=F,message=F, eval =F}
library("SingleR")
library("celldex") 
library("SummarizedExperiment") 
```

### load reference dataset

Since I did not know if this dataset comes from a human or a mouse, I loaded both (now I know that mice's genes have certain capital letters)

```{r load_reference,warning=F,message=F}
# Loading Human Primary Cell Atlas dataset (Mabbott et al. 2013) as the reference 
ref.data.human <- celldex::HumanPrimaryCellAtlasData()
ref.data.mice <- celldex::MouseRNAseqData()
```

Converting the dataset into a sinclecellexperiment object, needed for the analysis.

```{r}
sce.data <- as.SingleCellExperiment(DietSeurat(data.filt))
```

## Predict cell type

We will try to match my dataset against both human and mice annotations, because you never know.

```{r cell_type_prediction,warning=F,message=F}

predictions.human <- SingleR(test=sce.data, 
    ref=ref.data.human, labels=ref.data.human$label.main, fine.tune = TRUE, prune = TRUE) 

predictions.mice <- SingleR(test=sce.data, 
    ref=ref.data.mice, labels=ref.data.mice$label.main, fine.tune = TRUE, prune = TRUE) 
```

Once assigned a label, we now use a heatplot to visualize the results.

```{r scores_heatmap, warning=F, message=F, fig.width=8, fig.height=5}
plotScoreHeatmap(predictions.human)
```

```{r, warning=F, message=F, fig.width=8, fig.height=5}
plotScoreHeatmap(predictions.mice)
```

From these results, we can probably guess that the sample comes from mice (because more than half of the cells do not show any expression pattern that matches human annotations).
In addition, the tissue in analysis is mainly composed by:
- Hepatocytes: These are the main functional cells of the liver responsible for various metabolic activities, including detoxification, protein synthesis, and the production of bile.
- Endothelial cells: These cells line the blood vessels within the liver and play a role in regulating blood flow and facilitating exchange of substances between the blood and liver tissue.
- Epithelial cells: In the liver, epithelial cells are found lining the bile ducts, which transport bile produced by hepatocytes to the gallbladder and small intestine.
- Fibroblasts: These are connective tissue cells found throughout the liver tissue. They produce collagen and other proteins that provide structural support to the liver.
- Erythrocytes: While erythrocytes (red blood cells) are not typically considered part of liver tissue, they do pass through the liver within blood vessels, as the liver receives blood from the hepatic artery and portal vein.
From these insights, we can probably guess that this tissue is probably hepatic.

