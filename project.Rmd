---
title: "Single cell Project"
author: "Vittoria Ossanna"
output: html_notebook
editor_options: 
  markdown: 
    wrap: sentence
---

#### Load the necessary packages to perform the analysis

```{r, warning = F, message = F}

library(tidyverse) # collection of packages for tidy data analysis (ggplot, dplyr, ...)
library(Seurat) # single cell analysis (Check that the version is at least 4.0.0)
library(patchwork) # combine separate ggplots into the same graphic
```

### Reading the data

In this step, I am loading data from the file VPV.rds, a file containing an unknown sample obtained from either mice or human tissues.
After tissue dissociation, cells were sorted by FACS and scRNA-seq libraries were prepared with the Smart-Seq2 protocol/platform.
The starting point is a digital count matrix with mouse or human genes as features.

```{r, warning = F, message = F}
data.raw <- readRDS("./data/VPV.rds")
```

In this step, I am initializing the Seurat object with the digital count matrix.
We are starting with a count table containing 4148 samples and 23433 features (as genes).

```{r, warning = F, message = F}
data <- CreateSeuratObject(counts = data.raw)
```

# 1. Quality control and filtering

In the current Section, I use standard methods of quality control and filtering to obtain a cleaned matrix of data.

## Filtering based on the percentage of mitocondrial, ribosomial and hemoglobin genes

We filter out genes with increased number of genes that map to a mitocondrial genome because low-quality or dying cells often exhibit extensive mitochondrial contamination.
In the same manner we will calculate the proportion gene expression that comes from ribosomal proteins.
Finally, with the same method we will calculate proportion hemoglobin genes, which can give an indication of red blood cell contamination.
I believe that this control has no use in this project because I do not know the composition of my sample, therefore, avoiding to consider hemoglobin-related genes could lead to errors.

As indicated in the assignment, mitochondrial genes might be missing from the count matrix, therefore I used spike-in RNAs, all starting with "ERCC", as an alternative quality control.
ERCC stands for External RNA Controls Consortium.

```{r qc_metrics, warning=F, message=F}
data[["percent_mt"]] <- PercentageFeatureSet(data, pattern = "^MT-")
data[["percent_ribo"]] <- PercentageFeatureSet(data, "^RP[SL]")
# data[["percent_hb"]] <- PercentageFeatureSet(data, "^HB[^(P)]")
max(data[["percent_mt"]])
max(data[["percent_ribo"]])
# max(data[["percent_hb"]])

data[["percent_ERCC"]] <- PercentageFeatureSet(data, "^ERCC")
max(data[["percent_ERCC"]])
```

From this analysis, it seems that there is no instance that correspond to any of these genes.
Anyhow, the alternative filtering based on ERCC seems to produce non-null values.
I will use in the next steps this percentage for filtering.

### Updating dataset with ERCC filtering

This chunk is dedicate to the update of the data excluding all cells that present more than 5% of genes belonging to ERCC.

```{r}
data <- subset(data, percent_ERCC < 5)
```

## Filtering based on unique number of genes detected in each cell and total number of molecules detected within a cell

A standard approach is to filter cells with low amount of reads as well as genes that are present in at least a certain amount of cells.
Here we will only consider cells with at least 200 detected genes and genes need to be expressed in at least 3 cells.

```{r}
# selecting all features and cells with minimum requirement
selected_c <- WhichCells(data, expression = nFeature_RNA > 200)
selected_f <- rownames(data)[Matrix::rowSums(data) > 3]

data.filt <- subset(data, features = selected_f, cells = selected_c)
# dim(data.filt)
```

Extremely high number of detected genes could indicate doublets.
However, depending on the cell type composition in my sample, I may have cells with higher number of genes (and also higher counts) from one cell type.

I found these thresholds online [here](https://nbisweden.github.io/workshop-scRNAseq/labs/compiled/seurat/seurat_01_qc.html#Calculate_QC)

```{r}
# eliminate cells with an increased number of reads
# to define the upper bound, we get the median number of counts. We wxclude from the final evaluation all cells that present a number of Counts greater than twice the median number of counts.
# high.data1 <- WhichCells(data.filt, expression = nCount_RNA > 2 * median(data.filt$nCount_RNA))
```

how toma likes it: we plot a violin pf the counts, and we expect three areas: one in which we have the desired data, one in which we have too little counts, and one in which we have artifacts, as doublets. We use graphical insignt from this plot to find a threshold for doublets.

```{r}
dim(data.filt)

# from this plot we can define a lower and upper bound for out cleaning
VlnPlot(data.filt, features = c("nCount_RNA"), y.max = 3e+6) & geom_hline(yintercept = 750000) & geom_hline(yintercept = 100000)

high.data <- WhichCells(data.filt, expression = nCount_RNA > 750000)
low_data <- WhichCells(data.filt, expression = nCount_RNA < 100000)

# remove these cells
final.data <- setdiff(WhichCells(data.filt),c(high.data, low_data))

# update the dataset with only genes that passed the filetring
data.filt <- data.filt[, colnames(data.filt) %in% final.data]

# check dimension of final filtered dataset
dim(data.filt)

```

### Plot QC for ERCC genes

Now we can plot some of the QC-features to get visual insights.

```{r}
p1<- VlnPlot(data.filt, features = c("nFeature_RNA", "nCount_RNA", "percent_ERCC"), ncol = 2, pt.size = 0.01)

p1
```

```{r qc_scatter, warning=F, message=F}

plot1 <- FeatureScatter(data.filt, feature1 = "nCount_RNA", feature2 = "percent_ERCC")
plot2 <- FeatureScatter(data.filt, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
plot1 + plot2

```

## Filtering considerations

From the filtering based on presence of ERCC (excluding all cells that present more than 5% of ERCC transcripts detected) and the filtering based on a lower bound of counts (for both cells and genes) and upper bound (associated to Doublets), I recovered a dataset that contains 2284 cells and 22012 features.

# 2. Normalization, identification of variable features, scaling

## Data Normalization

In the realm of data analysis, ensuring proper normalization for both inter-sample and intra-sample comparisons is crucial to obtain unbiased results.
To achieve this goal in the current project, I employ a Log-Normalization method.
This approach normalizes the measurement of feature expression for each cell based on the total expression, applies a scaling factor, and subsequently transforms the results using a logarithmic function.
The resulting normalized data is stored within the `data.filt[["RNA"]]@data` container.

```{r, warning = F, message=F}

data.filt <- NormalizeData(data.filt, 
                           normalization.method = "LogNormalize", 
                           scale.factor = 10000)

# data.filt[["RNA"]]@data[1:10, 1:30]

```

## Feature Selection

In this section, I isolate a subset of features characterized by significant cell-to-cell variability.
Concentrating on these genes in subsequent analyses enhances the ability to emphasize biological signals within single-cell datasets.

```{r, message = F}
data.filt <- FindVariableFeatures(data.filt, 
                                  selection.method = "vst", 
                                  nfeatures = 2000)

top10 <- head(VariableFeatures(data.filt), 10)

plot1 <- VariableFeaturePlot(data.filt)
plot2 <- LabelPoints(plot = plot1, points = top10, repel = T)

plot2

```

## Scaling

In this section, i perform a linear transformation to the expresison levels of each gene.
This is a standard pre-processing step which is often used before performing dimensionality reduction.
Since - at the end of the day - we are interested in the genes which are expressed in the most different way - we perform this scaling only on the top 2000 genes (identified before).

```{r, warning= F, message=F}
all_genes <- rownames(data.filt)

data.filt <- ScaleData(data.filt, 
                       fetaures = all_genes)

# data.filt[["RNA"]]@scale.data[1:5, 1:10]
```

# 3. Dimensionality reduction

Dimensionality reduction techniques are employed to reduce data complexity in downstream analyses (e.g. clustering) and for data visualization.

## PCA

PCA, or Principal Component Analysis, is a technique used to simplify complex data by transforming it into a lower-dimensional representation while retaining as much original information as possible.
It achieves this by finding a set of new variables called principal components that are uncorrelated and ranked by the amount of variance they explain.
PCA is useful for reducing data dimensionality, preserving essential information, and revealing underlying patterns.

```{r, message=F, warning=F}
data.filt <- RunPCA(data.filt, 
                    features = VariableFeatures(object = data.filt))

DimPlot(data.filt, reduction = "pca",label = F)
```

PCA is highly interpretable and efficient, nevertheless it is often not a good idea to use such dimentionality reduction method with Single Cell data, due to their high sparsity and non-linear stucture of the data.
For this reason, I use two different non-linear method in the next section to overcome this problem.

### Define number of relevant components

For next steps, I need to derive a proper number of dimensions to use.
In order to do so, I use the euristic method of the elbow plot: a ranking of principle components based on the percentage of variance explained by each one.

```{r}
ElbowPlot(data.filt, ndims = 50)
```

From this plot, we cannot clearly see an elbow, but we can see a slow decrease of the deviation from component 7 on.
Anyway, I consider a more conservative approach including in the next steps 14 dimensions.
Or maybe I can keep 7?
I REALLY DO NOT KNOW, I will try both and see what gives better results.
From what I understand, the usage of tSNE or UMAP is simply slower than PCA, for this reason we use a number of relevant dimensions that we got from PCA in order to fasten up their processes.
Since the overall dataset would consists in thousands of features, it does not make much sense only to use 7 (even in the elbow is there).
If I use 30 or 50 feature, the process would be fasten up anyway woth a great improvement, without losing to much information.

## t-SNE

t-SNE (t-Distributed Stochastic Neighbor Embedding) is a dimensionality reduction technique used for visualizing complex high-dimensional data.
It works by calculating pairwise similarities between data points, emphasizing close similarities and using Gaussian distributions to define relationships.
It then maps the data to a lower-dimensional space (typically two dimensions) while preserving these pairwise similarities.
t-SNE employs an iterative optimization process to position data points in the lower-dimensional map, ensuring that similar data points remain close, while dissimilar ones are separated.
This makes it a valuable tool for exploring and visualizing intricate data structures and identifying clusters or patterns within the data.

```{r}
data.filt <- RunTSNE(data.filt, 
                     dims = 1:50)
DimPlot(data.filt, reduction = "tsne")
```

## UMAP

UMAP (Uniform Manifold Approximation and Projection) is another dimensionality reduction technique used for visualizing and exploring high-dimensional data.
It shares similarities with t-SNE but offers certain advantages.
UMAP constructs a low-dimensional representation by first modeling the data as a topological graph.
It focuses on preserving both local and global relationships among data points, leading to more balanced embeddings.
UMAP is known for its efficiency and ability to handle larger datasets compared to t-SNE.
It has gained popularity in various fields for tasks such as visualization, clustering, and data analysis, making it a valuable tool for uncovering patterns and structures within complex datasets.
From 2018, UMAP is considered the gold standard for Single Cell analysis.
In addition, it preserves better than t-SNE the local and global structure of the data.
Nevertheless, UMAP results decrease their interpretability.

```{r, message=F, warning=F}
data.filt <- RunUMAP(data.filt,
                     dims = 1:50)

DimPlot(data.filt, reduction = "umap")
```

# 4. Clustering

The clustering is based on a number of component defined during the PCA.
The function implied construct a graph where each cell correspod to a node, and tries to find cliques where the archs are constructed based on the similarity of the expression pattern of two cells.
To cluster the cells we run modularity optimization to group cells into clusters.

```{r, warning=F, message=F}

data.filt <- FindNeighbors(data.filt, dims = 1:50)
data.filt <- FindClusters(data.filt, resolution = 0.5)

head(Idents(data.filt), 5)

```

We now plot again PCA, tSNE and UMAP with labels from clustering to graphically visualize the clustering procedure.

```{r}
DimPlot(data.filt, reduction = "pca")
DimPlot(data.filt, reduction = "tsne")
DimPlot(data.filt, reduction = "umap")
```

# 5. Identification of marker genes

We make use of differential expression analysis to identify marker genes.
I will perform a differential expression analysis of each group against every other group (1 vs all).

```{r all_markers, warning=F, message=F}

markers <- FindAllMarkers(data.filt, 
                               only.pos = TRUE, 
                               min.pct = 0.25, 
                               logfc.threshold = 0.25)

top_markers <- markers %>%
    group_by(cluster) %>%
    # order(pbmc_markers$p_val_adj) %>%
    slice_max(n=1,order_by=avg_log2FC)

list_of_markers = top_markers$gene

```

Differently to what did in the tutorial, I deciced to decrease both min.ptc and logfc.threshold to 0.1.
The first parameter it only has the function of making the process faster (I have all the time in the world), the second - if increased - also speeds up computation, but my decreasing it we can avoid missing weaker signal.
Overall, lower values slow down computation but gets more accurate.
IM NOT SURE THIS IS VALID, ASK TOMA

## Visualizing some marker genes

Here, I am plotting a graphic visualization of some of the genes found in the previous summary that exhibit extremely relevant adjusted p-values and high log-fold change.

```{r}
VlnPlot(data.filt, features = list_of_markers, pt.size = 0)
# RidgePlot(data.filt,features = list_of_markers)
FeaturePlot(data.filt, features = list_of_markers)
DotPlot(data.filt, features = list_of_markers)

```

# 6. Cell cycle analysis

The presence of cell cycle within scRNAseq data may introduce variability.
If the experiment does not focus on the cell cycle, strategies can be employed to address this heterogeneity.
In Seurat, handling cell cycle effects involves computing phase scores using established markers and then removing them during data pre-processing to alleviate the impact of cell cycle heterogeneity on scRNA-seq data.

### Conversion function

Since I am working with mouse genes, I need to convert (sooner or later) gene names from upper to lower case (except the first letter).
Here is a function to do this which will be used during the next steps.

```{r}
convertFirstLetterToUpper <- function(inputVector) {
  result <- sapply(inputVector, function(x) {
    paste0(toupper(substr(x, 1, 1)), tolower(substr(x, 2, nchar(x))))
  })
  return(result)
}
```

### Load marker genes

We use two list of marked (denoting G2/M and S cell phase) which will be use to find matches against the cell from our dataset and convert them into lower case (except first letter).

```{r, warning = F, message=F}

s_genes <- cc.genes$s.genes
s_genes <- convertFirstLetterToUpper(s_genes)
g2m_genes <- cc.genes$g2m.genes
g2m_genes <- convertFirstLetterToUpper(g2m_genes)

```

# Assign cell-cycle score and visualize markers

We assign to each cell a score.
based on presence or absence of the expression of the markers loaded previously.

```{r}

data.filt <- CellCycleScoring(data.filt, s.features = s_genes, g2m.features = g2m_genes, set.ident = T)
head(data.filt[[]], 10)

```

```{r ,warning=F,message=F}
RidgePlot(data.filt, features = c("Mcm5", "Pcna", "Hhgb2", "Cdk1"), ncol = 2)
```

Also this plot does not work because we do not have those specific markers in our feature set Running a PCA on cell cycle genes confirms that cells separate entirely by phase

```{r ,warning=F,message=F}

data.filt <- RunPCA(data.filt, features = c(s_genes, g2m_genes),verbose=F)
DimPlot(data.filt, reduction="pca")
table(data.filt$Phase)

```

By performing a PCA only on genes that are markers for s and g2 phase, we see that the majority of the cells are associated with G1 phase, as for the rest, we have a comparable number of cells in S and in G2 phase.
From the PCA, we can derive that most of the cells (even if not in G1 phase) are spatially close to cells in G1.
Also, we clarely see a hyperplane separating S and G2 phase (horizontally).

# 7. Annotation

We now try to annotate the cell with some annotated dataset.

For each cell in the unknown dataset: 1.
Compute the Spearman correlation between its expression profile and that of each reference sample (measure of robustness to batch effects across datasets) 2.
Define per-label score as a fixed quantile (by default, 0.8) of the correlations across all samples with that label (accounts for differences in the number of reference samples for each label) 3.
Repeat the score calculation for all labels in the reference dataset.
The label with the highest score is used as SingleR's prediction for this cell.

### load required libraries

```{r load_packages,warning=F,message=F, eval =F}
library("SingleR")
library("celldex") 
library("SummarizedExperiment") 
library("Seurat")
```

### load reference dataset

Since I do not know if this dataset comes from a human or a mouse, which other dataset should I load?

```{r load_reference,warning=F,message=F}
# Loading Human Primary Cell Atlas dataset (Mabbott et al. 2013) as the reference 
ref.data.human <- celldex::HumanPrimaryCellAtlasData()
ref.data.mice <- celldex::MouseRNAseqData()
```

Converting the dataset into a sinclecellexperiment object, needed for the analysis.

```{r}
sce.data <- as.SingleCellExperiment(DietSeurat(data.filt))
```

## Predict cell type

We will try to match my dataset against both human and mice annotations, because you never know.

```{r cell_type_prediction,warning=F,message=F}

predictions.human <- SingleR(test=sce.data, 
    ref=ref.data.human, labels=ref.data.human$label.main, fine.tune = TRUE, prune = TRUE) 

predictions.mice <- SingleR(test=sce.data, 
    ref=ref.data.mice, labels=ref.data.mice$label.main, fine.tune = TRUE, prune = TRUE) 
```

Once assigned a label, we now use a heatplot to visualize the results.

```{r scores_heatmap, warning=F, message=F, fig.width=8, fig.height=5}

plotScoreHeatmap(predictions.human)
plotScoreHeatmap(predictions.mice)

```

From these results, we can probably guess that the sample comes from mice (because more than half of the cells do not show any expression pattern that matches human annotations).
I do not know if this procedure is valid to assess this stuff.
Could this be liver tissue?
I think so.
